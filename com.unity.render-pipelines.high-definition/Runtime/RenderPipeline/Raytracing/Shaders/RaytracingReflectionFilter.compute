#pragma kernel RaytracingReflectionFilter
#pragma kernel TemporalAccumulationFilter

#pragma only_renderers d3d11

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/NormalBuffer.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/BSDF.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/PreIntegratedFGD/PreIntegratedFGD.hlsl"

// Raytracing Includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/OnlineVariance.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingConsts.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingSampling.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/ShaderVariablesRaytracing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/ScreenSpaceLighting/ScreenSpaceLighting.hlsl"

// Tile size of this compute
#define RAYTRACING_REFLECTION_TILE_SIZE 8

// Input textures for the spatial filtering
Texture2D<float>                    _DepthTexture;
Texture2DArray<float>               _NoiseTexture;
Texture2D<float4>                   _SsrLightingTextureRW;
Texture2D<float4>                   _SsrHitPointTexture;
Texture2D<float4>                   _SsrClearCoatMaskTexture;

// Output Textures for the spatial filtering
RWTexture2D<float4>                 _RaytracingReflectionTexture;
RWTexture2D<float>                  _VarianceTexture;
RWTexture2D<float3>                 _MaxColorRangeTexture;
RWTexture2D<float3>                 _MinColorRangeTexture;
int                                 _SpatialFilterRadius;

// Input and Output data of the temporal accumulation pass
RWTexture2D<float4>                 _CurrentFrameTexture;
RWTexture2D<float4>                 _AccumulatedFrameTexture;
float                               _TemporalAccumuationWeight;

[numthreads(RAYTRACING_REFLECTION_TILE_SIZE, RAYTRACING_REFLECTION_TILE_SIZE, 1)]
void RaytracingReflectionFilter(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    // Compute the half res coordinate that we shall be using for our effect
    uint2 fullResCoord = dispatchThreadId.xy;
    uint2 halfResCoord = fullResCoord / 2;

    // Compute the index of the noise texture to use
    int noiseIndex = (int)(clamp((int)(_ScramblingTexture[halfResCoord].y * 32.0f), 0, 31));

    // Compute the subpixel index that matches this full screen pixel.
    int localIndex = (fullResCoord.x & 1) + (fullResCoord.y & 1) * 2;

    // Fetch the depth
    float depth = LOAD_TEXTURE2D(_DepthTexture, fullResCoord).x;

    NormalData normalData;
    DecodeFromNormalBuffer(fullResCoord, normalData);

    // We use a texture to identify if we use a clear coat constant for perceptualRoughness for SSR or use value from normal buffer.
    // When we use a forward material we can output the normal and perceptualRoughness for the coat for SSR, so we simply bind a black 1x1 texture
    // When we use deferred material we need to bind the gbuffer2 and read the coat mask
    float4 coatMask = _SsrClearCoatMaskTexture[fullResCoord];
    normalData.perceptualRoughness = HasClearCoatMask(coatMask) ? CLEAR_COAT_PERCEPTUAL_ROUGHNESS : normalData.perceptualRoughness;
    // Fetch the roughness
    float roughness = PerceptualRoughnessToRoughness(normalData.perceptualRoughness);

    // Duplicating same early out condition we do on reflection dispatchrays as that info is 1/2 res while we need full res granularity here.
    // Also, this operates on data we fetch anyway, while the _SsrLightingTextureRW at central pixel is needed only if that pixel contributes to filtering below. 
    if (depth == UNITY_RAW_FAR_CLIP_VALUE || PerceptualRoughnessToPerceptualSmoothness(normalData.perceptualRoughness) < _RaytracingReflectionMinSmoothness)
        return;

    // Fetch the normal WS
    float3 normalWS = normalData.normalWS;

    // Compute the world space position
    PositionInputs posInput = GetPositionInput_Stereo(fullResCoord, _ScreenSize.zw, depth, UNITY_MATRIX_I_VP, UNITY_MATRIX_V, unity_StereoEyeIndex);
    float3 positionWS = GetAbsolutePositionWS(posInput.positionWS);

    // Compute the view in world space
    float3 viewWS = normalize(_WorldSpaceCameraPos - positionWS);

    // Compute the reflected direction for this view direction
    float3 reflDir = reflect(-viewWS, normalWS);

    // Initialize the output pixels
    float4 resultSum = float4(0.0 ,0.0, 0.0, 0.0);
    float3 minColorRange = float3(1000.0, 1000.0, 1000.0);
    float3 maxColorRange = float3(0.0, 0.0, 0.0);
    uint sampleCount = 0;

    VarianceEstimator variance;
    InitializeVarianceEstimator(variance);

    float radiusSq = _SpatialFilterRadius * _SpatialFilterRadius;
    
    for(int y = -_SpatialFilterRadius; y < _SpatialFilterRadius; ++y)
    {
        for(int x = -_SpatialFilterRadius; x < _SpatialFilterRadius; ++x)
        {
            float radiusDistanceSq = (y*y + x*x);
            if(radiusDistanceSq > radiusSq) continue;

            // Compute the noise position that shall be used
            int2 relativeHRShift = uint2(8 + x, 8 + y);

            // Full res sample position
            int2 sourceCoord = (halfResCoord + uint2(x,y)) * 2;

            // If this pixel is outside of the screen, we cannot use it
            if(sourceCoord.x < 0 || sourceCoord.x > _ScreenSize.x 
                || sourceCoord.y < 0 || sourceCoord.y > _ScreenSize.y) 
            continue;
            
            // Fetch the target color
            float4 sampleColor = _SsrLightingTextureRW[sourceCoord];

            // Compute the position of the actual source pixel
            uint subPixel =  clamp(floor(sampleColor.w * 4.0f), 0, 3);
            uint2 shift = HalfResIndexToCoordinateShift[subPixel];
            uint2 actualSourceCoord = sourceCoord + shift;

            // Fetch the Depth
            float sampleDepth = LOAD_TEXTURE2D(_DepthTexture, actualSourceCoord).x;
            // If this the background, it should not be used as a valid sample
            if(sampleDepth == 0.0f) continue;

            // Compute the target pixel that it will impact
            float sample = _NoiseTexture[int3(relativeHRShift, noiseIndex)].x;
            int index = clamp(floor(sample * 4.0f), 0, 3);

            if (index != localIndex) continue;

            // Let's fetch the half res sample's properties
            // Get the direction and pdf
            float4 directionPDF = _SsrHitPointTexture[sourceCoord];

            // If this direction is under the candidate surface, then it is not valid
            if(dot(directionPDF.xyz, normalWS) <= 0.0f) continue;

            // If this direction is not in the hemisphere of the reflected view direction, then it is not valid
            if(dot(directionPDF.xyz, reflDir) <= 0.0f) continue;

            // Compute the brdf of this sample
            float weight = 1.0f;
            if(roughness > 0.001)
            {
                // Compute the brdf of this sample
                float3 H = normalize(directionPDF.xyz + viewWS);
                float NdotH = dot(normalWS, H);
                float NdotL = dot(directionPDF.xyz, normalWS);
                float NdotV = dot(viewWS, normalWS);
                float localBRDF = D_GGX(NdotH, roughness) * V_SmithJointGGX(NdotL, NdotV, roughness) * NdotL;
                weight = localBRDF * directionPDF.w;
            }

            // Push the value to the variance estimation
            PushValue(variance, length(sampleColor.xyz));

            // Contirbute to all the output values
            float3 sampleResult = sampleColor.xyz * weight;
            resultSum += float4(sampleResult, weight);
            minColorRange = min(minColorRange[index], sampleResult);
            maxColorRange = max(maxColorRange[index], sampleResult);
            sampleCount += 1;
        }
    }

        // Compute the full res coordinate
        if(depth == 0.0f || sampleCount == 0)
        {
            _RaytracingReflectionTexture[fullResCoord] = float4(0.0f, 0.0f, 0.0f, 0.0f);
            _VarianceTexture[fullResCoord] = 1.0f;
            _MaxColorRangeTexture[fullResCoord] = float3(0.0, 0.0, 0.0);
            _MinColorRangeTexture[fullResCoord] = float3(1.0, 1.0, 1.0);
        }
        else
        {
            _RaytracingReflectionTexture[fullResCoord] = float4((resultSum.xyz / resultSum.w), roughness);
            _VarianceTexture[fullResCoord] = saturate(Variance(variance));
            _MaxColorRangeTexture[fullResCoord] = maxColorRange;
            _MinColorRangeTexture[fullResCoord] = minColorRange;
        }
}

[numthreads(RAYTRACING_REFLECTION_TILE_SIZE, RAYTRACING_REFLECTION_TILE_SIZE, 1)]
void TemporalAccumulationFilter(uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    // Fetch the current pixel coordinate
    uint2 currentCoord = groupId * RAYTRACING_REFLECTION_TILE_SIZE + groupThreadId;

    // Fetch the previous color
    float3 previousColor = _AccumulatedFrameTexture[currentCoord].xyz;
    bool previousValidityFlag = _AccumulatedFrameTexture[currentCoord].w > 0.0f;

    // Fetch the color range that we need to check before using
    float3 colorMinBound = _MinColorRangeTexture[currentCoord].xyz;
    float3 colorMaxBound = _MaxColorRangeTexture[currentCoord].xyz;

    // check if the previous color is in the bounds
    // TODO: Try to do the comparison in Lab for better results http://www.brucelindbloom.com/index.html?Math.html
    bool colorInBound = colorMinBound.x < previousColor.x && colorMaxBound.x > previousColor.x 
                        && colorMinBound.y < previousColor.y && colorMaxBound.y > previousColor.y 
                        && colorMinBound.z < previousColor.z && colorMaxBound.z > previousColor.z;

    // Validity flag of the current sample
    float validityFlag = all(colorMinBound > colorMaxBound);
    
    float3 combinedColor = float3(0.0f, 0.0f, 0.0f);
    if(previousValidityFlag && colorInBound)
    {
        // Compute the accumulation factor for this surface (using the user parameter and the rouhgness of the surface)
        float accumulationFactor = _CurrentFrameTexture[currentCoord].w < 0.001f ? 1.0 : _TemporalAccumuationWeight;  

        // Previous pixel is valid
        combinedColor = (_CurrentFrameTexture[currentCoord].xyz * accumulationFactor + _AccumulatedFrameTexture[currentCoord].xyz * (1.0 - accumulationFactor));
    }
    else
    {
        // Previous pixel is invalid, override it
        combinedColor = _CurrentFrameTexture[currentCoord].xyz;
    }
    
    _AccumulatedFrameTexture[currentCoord] = float4(combinedColor, validityFlag);
    _CurrentFrameTexture[currentCoord] = float4(combinedColor, validityFlag);
}
